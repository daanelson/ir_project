{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Model training for DRMM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import make_test_data\n",
    "import pickle as pkl\n",
    "import os\n",
    "import pdb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#TODO: fix root, remove key restrictions\n",
    "\n",
    "# Placeholder data parsing\n",
    "def get_data(histograms, training_year=2014, training=True):\n",
    "    # Proposed format: [doc_id topic_id h0 h1 h2 h3 ...]\n",
    "    #data_root = '/scratch/cluster/dnelson/ir_proj'\n",
    "\n",
    "    # can set this to 2015 to read in annotations for 2015 instead\n",
    "    # format: label_dict[doc_id][topic_id] = ground truth\n",
    "    label_dict = make_test_data.make_truth(training_year)\n",
    "\n",
    "    # enforcing order on a dictionary & downsampling to only data w/judgments for training\n",
    "    key_array = histograms.keys()\n",
    "    if training:\n",
    "        key_array = [val for val in key_array if label_dict[int(val[0])][int(val[1])+1] >= 0]\n",
    "\n",
    "    X = np.array([[np.log(val) if val > 0 else val for val in histograms[key]] for key in key_array])\n",
    "    Y = np.array([int(label_dict[int(key[0])][int(key[1])+1] > 0) for key in key_array])\n",
    "    return X, Y, key_array\n",
    "\n",
    "def get_dict(training_year=2014):\n",
    "    data_root = '/Users/Dan/class/deep_ir/project/data'\n",
    "    \n",
    "    with open(os.path.join(data_root, 'term_histograms_%d' % training_year), 'r') as f:\n",
    "        histograms = pkl.load(f)\n",
    "    return histograms\n",
    "\n",
    "\n",
    "def get_fake_data():\n",
    "    X_train = np.random.rand(1000, 29)\n",
    "\n",
    "    # roughly uniform dist of 0, 0.5, 1\n",
    "    rand_vals = np.random.rand(1000)\n",
    "    Y_train = np.array([np.floor(val * 3)/2.0 for val in rand_vals])\n",
    "    return X_train, Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get all data for maximum iteration funtime power\n",
    "# THIS IS THE LONG PART\n",
    "train_dict = get_dict(training_year=2014)\n",
    "test_dict = get_dict(training_year=2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qrels2014.txt\n",
      "qrels-treceval-2015.txt\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, _ = get_data(train_dict, training_year=2014, training=True)\n",
    "#X_train, Y_train = get_fake_data()\n",
    "X_test, Y_test, test_keys = get_data(test_dict, training_year=2015, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ASIDE - this is how you make your own loss function. Not necessary but fun to play with.\n",
    "from keras import backend as K\n",
    "\n",
    "def supercool_loss(y_true, y_pred):\n",
    "    return K.mean(K.abs(y_true*10 - y_pred))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.regularizers import l1, activity_l1, l2\n",
    "from keras.layers import Input, LSTM, Dense, merge, Dropout\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create model (input_shape is inferred after first layer)\n",
    "# This model is a regression\n",
    "\n",
    "# Defines all shared weight layers for feedforward network\n",
    "num_inputs = 3\n",
    "shared_dense = Dense(5, activation='relu')\n",
    "shared_dropout = Dropout(0.5)\n",
    "shared_score = Dense(1, activation='relu')\n",
    "\n",
    "# constr\n",
    "inputs = [Input(shape=(29,)) for val in range(num_inputs)]\n",
    "output_1 = [shared_dense(val) for val in inputs]\n",
    "output_d = [shared_dropout(val) for val in output_1]\n",
    "output_score = [shared_score(val) for val in output_d]\n",
    "concat_vals = merge(output_score, mode='concat', concat_axis=-1)\n",
    "\n",
    "# Defines term weighting network\n",
    "shared_term_weight = Dense(1, activation='relu')\n",
    "term_weight_list = [shared_term_weight(val) for val in inputs]\n",
    "term_weights = merge(term_weight_list, mode='concat', concat_axis=-1)\n",
    "\n",
    "# Dot product over terms to weight them properly\n",
    "output = merge([concat_vals, term_weights], mode='dot')\n",
    "\n",
    "\n",
    "model = Model(input=inputs, output=output)\n",
    "# Compile model\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=1.)\n",
    "model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "31403/31403 [==============================] - 5s - loss: 1.4916 - binary_accuracy: 0.9075     \n",
      "Epoch 2/5\n",
      "31403/31403 [==============================] - 5s - loss: 1.4916 - binary_accuracy: 0.9075     \n",
      "Epoch 3/5\n",
      "31403/31403 [==============================] - 4s - loss: 1.4916 - binary_accuracy: 0.9075     \n",
      "Epoch 4/5\n",
      "31403/31403 [==============================] - 5s - loss: 1.4916 - binary_accuracy: 0.9075     \n",
      "Epoch 5/5\n",
      "31403/31403 [==============================] - 4s - loss: 1.4916 - binary_accuracy: 0.9075     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16dfc0dd0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train needs to be a list of numpy arrays\n",
    "X_new_train = [X_train for val in range(num_inputs)]\n",
    "model.fit(X_new_train, Y_train, nb_epoch=5, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "categorical_labels = to_categorical(Y_train, nb_classes=None)\n",
    "print categorical_labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.22982793]\n"
     ]
    }
   ],
   "source": [
    "# Test model\n",
    "pred_ranks = model.predict(X_test)\n",
    "print max(pred_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#[0][0] = id, [0][1] = topic, [1] = rank\n",
    "ranks_and_keys = zip(test_keys, pred_ranks)\n",
    "result_dict = defaultdict(lambda: [])\n",
    "for val in ranks_and_keys:\n",
    "    result_dict[val[0][1]].append((val[1][0], val[0][0]))\n",
    "\n",
    "with open('cat_query_results','wb') as f:\n",
    "    for cur_topic in range(30):\n",
    "        topic_results = result_dict[str(cur_topic)]\n",
    "        topic_results.sort(reverse=True)\n",
    "\n",
    "        for result_rank, cur_result in enumerate(topic_results[:1000]):\n",
    "            line_to_write = [str(cur_topic + 1), '0', str(cur_result[1]), str(result_rank + 1), str(cur_result[0]), 'test_run', '\\n']\n",
    "            f.write(\" \".join(line_to_write))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.22982793]\n"
     ]
    }
   ],
   "source": [
    "print max(pred_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print int(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('2794284', '20'), ('3510867', '23'), ('2275225', '21'), ('3658214', '26'), ('2830982', '4'), ('2533397', '5'), ('3838404', '12'), ('1570135', '7'), ('3565924', '6'), ('3274658', '12')]\n"
     ]
    }
   ],
   "source": [
    "print train_dict.keys()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0   0   0   0   0   0   0   0   1  10  93 301 428 335  90  39\n",
      "   9   5   4   0   0   0   0   0   0   0   1]\n",
      "[  0   0   0   0   0   0   0   0   0   0   4  27 189 504 524 399 188  85\n",
      "  35  25   5   1   0   0   1   0   0   0   2]\n",
      "[  0   0   0   0   0   0   0   0   0   0   2  20  84  96 111  62  25  13\n",
      "   2   0   0   0   0   0   0   0   0   0   0]\n",
      "[ 0  0  0  0  0  0  0  0  0  0  0  0  9 57 82 56 34  8  8  4  1  0  0  0  0\n",
      "  0  0  0  2]\n",
      "[  0   0   0   0   0   0   0   0   0   0   1  35 150 406 558 502 233 134\n",
      "  54  13   4   3   0   2   1   1   0   0   2]\n",
      "[  0   0   0   0   0   0   0   0   0   0   3  27 110 245 226 179  82  58\n",
      "   8  10   3   0   0   0   0   0   0   0   0]\n",
      "[  0   0   0   0   0   0   0   0   0   0   3  34 117 232 273 135  86  42\n",
      "   6  12   1   0   0   1   1   1   0   0   1]\n",
      "[  0   0   0   0   0   0   0   0   0   0  16  75 258 451 560 394 219  84\n",
      "  54   2   2   0   0   0   0   0   0   0   0]\n",
      "[  0   0   0   0   0   0   0   0   0   0   2   8  66 371 435 424 195  75\n",
      "  60  20   5  10   1   0   0   0   0   0   0]\n",
      "[ 0  0  0  0  0  0  0  0  0  0  2  8 22 63 85 74 47 30 16  8  4  0  0  0  0\n",
      "  0  0  0  1]\n"
     ]
    }
   ],
   "source": [
    "for val in train_dict.keys()[:10]:\n",
    "    print train_dict[val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31403, 3, 29)\n"
     ]
    }
   ],
   "source": [
    "thing = [[val, val, val] for val in X_train]\n",
    "print np.array(thing).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31403, 29)\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_1 = [shared_dense(val) for val in inputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'Relu_2:0' shape=(?, 5) dtype=float32>, <tf.Tensor 'Relu_3:0' shape=(?, 5) dtype=float32>, <tf.Tensor 'Relu_4:0' shape=(?, 5) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "print output_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
